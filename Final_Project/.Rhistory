scale_color_hue(labels = c('Closing Price', '20 Day Moving Average', '5 Day Moving Average')) +
scale_x_date(date_breaks = 'one year')
labs(title = paste('Moving Averages for', cmdty), x = 'Date', y = 'Closing Price')
qdt
qdt <- qdt %>%
ggplot(aes(x = date, y = price, colour = type)) +
geom_line() +
scale_color_hue(labels = c('Closing Price', '20 Day Moving Average', '5 Day Moving Average')) +
scale_x_date(date_breaks = '1 year')
#
# Use the 'tidyquant' package to calculate the 5- and 20-day simple moving averages. Add columns, and select only those.
#
qdt <- qdt %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 5) %>%
rename(SMA.5 = SMA) %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 20) %>%
rename(SMA.20 = SMA) %>%
select(date, close, SMA.5, SMA.20) %>%
gather(key = type, value = price, close:SMA.20)
#
# Pick a stock at random from the DJIA
#
cmdty <- sample(tabl1$Symbol, 1)
cmdty
#
# Register Quandl API Key
#
quandl.api.key <- read.table("quandl_api.txt", stringsAsFactors=F)[[2]]
Quandl.api_key(quandl.api.key)
#
# Only include weekdays. Reference: https://stackoverflow.com/questions/13673895/r-time-series-data-daily-only-working-days
#
tS <- timeSequence(Sys.Date()-200, Sys.Date())
# Subset weekdays
tW <- tS[isWeekday(tS)]
tW <- as.list(tW)
qdt <- Quandl.datatable('WIKI/PRICES', date=tW, ticker=cmdty)
#
# Use the 'tidyquant' package to calculate the 5- and 20-day simple moving averages. Add columns, and select only those.
#
qdt <- qdt %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 5) %>%
rename(SMA.5 = SMA) %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 20) %>%
rename(SMA.20 = SMA) %>%
select(date, close, SMA.5, SMA.20) %>%
gather(key = type, value = price, close:SMA.20)
qdt <- qdt %>%
ggplot(aes(x = date, y = price, colour = type)) +
geom_line() +
scale_color_hue(labels = c('Closing Price', '20 Day Moving Average', '5 Day Moving Average')) +
scale_x_date(date_breaks = '1 year')
labs(title = paste('Moving Averages for', cmdty), x = 'Date', y = 'Closing Price')
qdt
qdt <- qdt %>%
ggplot(aes(x = date, y = price, colour = type)) +
geom_line() +
scale_color_hue(labels = c('Closing Price', '20 Day Moving Average', '5 Day Moving Average')) +
scale_x_date(date_breaks = '1 month')
#
# Pick a stock at random from the DJIA
#
cmdty <- sample(tabl1$Symbol, 1)
cmdty
#
# Register Quandl API Key
#
quandl.api.key <- read.table("quandl_api.txt", stringsAsFactors=F)[[2]]
Quandl.api_key(quandl.api.key)
#
# Only include weekdays. Reference: https://stackoverflow.com/questions/13673895/r-time-series-data-daily-only-working-days
#
tS <- timeSequence(Sys.Date()-200, Sys.Date())
# Subset weekdays
tW <- tS[isWeekday(tS)]
tW <- as.list(tW)
qdt <- Quandl.datatable('WIKI/PRICES', date=tW, ticker=cmdty)
#
# Use the 'tidyquant' package to calculate the 5- and 20-day simple moving averages. Add columns, and select only those.
#
qdt <- qdt %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 5) %>%
rename(SMA.5 = SMA) %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 20) %>%
rename(SMA.20 = SMA) %>%
select(date, close, SMA.5, SMA.20) %>%
gather(key = type, value = price, close:SMA.20)
qdt <- qdt %>%
ggplot(aes(x = date, y = price, colour = type)) +
geom_line() +
scale_color_hue(labels = c('Closing Price', '20 Day Moving Average', '5 Day Moving Average')) +
scale_x_date(date_breaks = '1 month')
labs(title = paste('Moving Averages for', cmdty), x = 'Date', y = 'Closing Price')
qdt
#
# Pick a stock at random from the DJIA
#
cmdty <- sample(tabl1$Symbol, 1)
cmdty
#
# Register Quandl API Key
#
quandl.api.key <- read.table("quandl_api.txt", stringsAsFactors=F)[[2]]
Quandl.api_key(quandl.api.key)
#
# Only include weekdays. Reference: https://stackoverflow.com/questions/13673895/r-time-series-data-daily-only-working-days
#
tS <- timeSequence(Sys.Date()-200, Sys.Date())
# Subset weekdays
tW <- tS[isWeekday(tS)]
tW <- as.list(tW)
qdt <- Quandl.datatable('WIKI/PRICES', date=tW, ticker=cmdty)
#
# Use the 'tidyquant' package to calculate the 5- and 20-day simple moving averages. Add columns, and select only those.
#
qdt <- qdt %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 5) %>%
rename(SMA.5 = SMA) %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 20) %>%
rename(SMA.20 = SMA) %>%
select(date, close, SMA.5, SMA.20) %>%
gather(key = type, value = price, close:SMA.20)
qdt <- qdt %>%
ggplot(aes(x = date, y = price, colour = type)) +
geom_line() +
scale_color_hue(labels = c('Closing Price', '20 Day Moving Average', '5 Day Moving Average')) +
scale_x_date(date_breaks = '1 month') +
scale_y_continuous(breaks=seq(145,180,3))
labs(title = paste('Moving Averages for', cmdty), x = 'Date', y = 'Closing Price')
qdt
#
# Pick a stock at random from the DJIA
#
cmdty <- sample(tabl1$Symbol, 1)
cmdty
#
# Register Quandl API Key
#
quandl.api.key <- read.table("quandl_api.txt", stringsAsFactors=F)[[2]]
Quandl.api_key(quandl.api.key)
#
# Only include weekdays. Reference: https://stackoverflow.com/questions/13673895/r-time-series-data-daily-only-working-days
#
tS <- timeSequence(Sys.Date()-200, Sys.Date())
# Subset weekdays
tW <- tS[isWeekday(tS)]
tW <- as.list(tW)
qdt <- Quandl.datatable('WIKI/PRICES', date=tW, ticker=cmdty)
#
# Use the 'tidyquant' package to calculate the 5- and 20-day simple moving averages. Add columns, and select only those.
#
qdt <- qdt %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 5) %>%
rename(SMA.5 = SMA) %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 20) %>%
rename(SMA.20 = SMA) %>%
select(date, close, SMA.5, SMA.20) %>%
gather(key = type, value = price, close:SMA.20)
qdt <- qdt %>%
ggplot(aes(x = date, y = price, colour = type)) +
geom_line() +
scale_color_hue(labels = c('Closing Price', '20 Day Moving Average', '5 Day Moving Average')) +
scale_x_date(date_breaks = '1 month') +
scale_y_continuous(breaks=seq(0,180,10))
labs(title = paste('Moving Averages for', cmdty), x = 'Date', y = 'Closing Price')
qdt
#
# Pick a stock at random from the DJIA
#
cmdty <- sample(tabl1$Symbol, 1)
cmdty
#
# Register Quandl API Key
#
quandl.api.key <- read.table("quandl_api.txt", stringsAsFactors=F)[[2]]
Quandl.api_key(quandl.api.key)
#
# Only include weekdays. Reference: https://stackoverflow.com/questions/13673895/r-time-series-data-daily-only-working-days
#
tS <- timeSequence(Sys.Date()-200, Sys.Date())
# Subset weekdays
tW <- tS[isWeekday(tS)]
tW <- as.list(tW)
qdt <- Quandl.datatable('WIKI/PRICES', date=tW, ticker=cmdty)
#
# Use the 'tidyquant' package to calculate the 5- and 20-day simple moving averages. Add columns, and select only those.
#
qdt <- qdt %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 5) %>%
rename(SMA.5 = SMA) %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 20) %>%
rename(SMA.20 = SMA) %>%
select(date, close, SMA.5, SMA.20) %>%
gather(key = type, value = price, close:SMA.20)
qdt <- qdt %>%
ggplot(aes(x = date, y = price, colour = type)) +
geom_line() +
scale_color_hue(labels = c('Closing Price', '20 Day Moving Average', '5 Day Moving Average')) +
scale_x_date(date_breaks = '1 month') +
scale_y_continuous(breaks=waiver())
labs(title = paste('Moving Averages for', cmdty), x = 'Date', y = 'Closing Price')
qdt
#
# Pick a stock at random from the DJIA
#
cmdty <- sample(tabl1$Symbol, 1)
cmdty
#
# Register Quandl API Key
#
quandl.api.key <- read.table("quandl_api.txt", stringsAsFactors=F)[[2]]
Quandl.api_key(quandl.api.key)
#
# Only include weekdays. Reference: https://stackoverflow.com/questions/13673895/r-time-series-data-daily-only-working-days
#
tS <- timeSequence(Sys.Date()-200, Sys.Date())
# Subset weekdays
tW <- tS[isWeekday(tS)]
tW <- as.list(tW)
qdt <- Quandl.datatable('WIKI/PRICES', date=tW, ticker=cmdty)
#
# Use the 'tidyquant' package to calculate the 5- and 20-day simple moving averages. Add columns, and select only those.
#
qdt <- qdt %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 5) %>%
rename(SMA.5 = SMA) %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 20) %>%
rename(SMA.20 = SMA) %>%
select(date, close, SMA.5, SMA.20) %>%
gather(key = type, value = price, close:SMA.20)
qdt <- qdt %>%
ggplot(aes(x = date, y = price, colour = type)) +
geom_line() +
scale_color_hue(labels = c('Closing Price', '20 Day Moving Average', '5 Day Moving Average')) +
scale_x_date(date_breaks = '1 month') +
scale_y_continuous(breaks=waiver()) +
theme(axis.text.x = element_text(angle = 45))
labs(title = paste('Moving Averages for', cmdty), x = 'Date', y = 'Closing Price')
qdt
#
# Pick a stock at random from the DJIA
#
cmdty <- sample(tabl1$Symbol, 1)
cmdty
#
# Register Quandl API Key
#
quandl.api.key <- read.table("quandl_api.txt", stringsAsFactors=F)[[2]]
Quandl.api_key(quandl.api.key)
#
# Only include weekdays. Reference: https://stackoverflow.com/questions/13673895/r-time-series-data-daily-only-working-days
#
tS <- timeSequence(Sys.Date()-200, Sys.Date())
# Subset weekdays
tW <- tS[isWeekday(tS)]
tW <- as.list(tW)
qdt <- Quandl.datatable('WIKI/PRICES', date=tW, ticker=cmdty)
#
# Use the 'tidyquant' package to calculate the 5- and 20-day simple moving averages. Add columns, and select only those.
#
qdt <- qdt %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 5) %>%
rename(SMA.5 = SMA) %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 20) %>%
rename(SMA.20 = SMA) %>%
select(date, close, SMA.5, SMA.20) %>%
gather(key = type, value = price, close:SMA.20)
qdt <- qdt %>%
ggplot(aes(x = date, y = price, colour = type)) +
geom_line() +
scale_color_hue(labels = c('Closing Price', '20 Day Moving Average', '5 Day Moving Average')) +
scale_x_date(date_breaks = '1 month') +
scale_y_continuous(breaks=waiver()) +
theme(axis.text.x = element_text(angle = 45))
labs(title = paste('Moving Averages for', cmdty), x = 'Date', y = 'Closing Price')
qdt
#
# Pick a stock at random from the DJIA
#
cmdty <- sample(tabl1$Symbol, 1)
cmdty
#
# Register Quandl API Key
#
quandl.api.key <- read.table("quandl_api.txt", stringsAsFactors=F)[[2]]
Quandl.api_key(quandl.api.key)
#
# Only include weekdays. Reference: https://stackoverflow.com/questions/13673895/r-time-series-data-daily-only-working-days
#
tS <- timeSequence(Sys.Date()-200, Sys.Date())
# Subset weekdays
tW <- tS[isWeekday(tS)]
tW <- as.list(tW)
qdt <- Quandl.datatable('WIKI/PRICES', date=tW, ticker=cmdty)
#
# Use the 'tidyquant' package to calculate the 5- and 20-day simple moving averages. Add columns, and select only those.
#
qdt <- qdt %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 5) %>%
rename(SMA.5 = SMA) %>%
tq_mutate(select = 6, mutate_fun = SMA, n = 20) %>%
rename(SMA.20 = SMA) %>%
select(date, close, SMA.5, SMA.20) %>%
gather(key = type, value = price, close:SMA.20)
qdt <- qdt %>%
ggplot(aes(x = date, y = price, colour = type)) +
geom_line() +
scale_color_hue(labels = c('Closing Price', '20 Day Moving Average', '5 Day Moving Average')) +
scale_x_date(date_breaks = '1 month') +
scale_y_continuous(breaks=waiver()) +
theme(axis.text.x = element_text(angle = 45))
labs(title = paste('Moving Averages for', cmdty), x = 'Date', y = 'Closing Price')
qdt
rm(quandl.api.key)
knitr::opts_chunk$set(echo = T,
cache = T,
stringsAsFactors = F)
library(tidyverse)
library(rvest)
library(httr)
library(jsonlite)
library(ggplot2)
library(stringr)
library(here)
library(data.table)
library(plotly)
#
# Incident count by boro
#
by_boro <- ggplot(data=merged, aes(boro, fill=boro)) +
labs(title = 'Incident Count by Boro')+
geom_bar()
load("~/GitHub/CUNY_MSDS/Fall_2017/DATA_607/Final Project/.RData")
#
# Merge both databases by each restaurant's phone number, then retain only unique values.
#
merged_dt <- merge(nyc.raw, yelp.results, by = 'phone')
merged <- merged_dt[!duplicated(merged_dt[c('phone', 'rating', 'record.date')]),]
#
# Add row for number of incidents by restaurant, and another for the restaurant's average score (higher = worse).
# Finally, remove irrelevant columns
#
merged <- merge(merged, count(merged_dt, camis), by='camis')
setnames(merged, 'n', 'incident_count')
avg_score <- group_by(merged_dt,camis) %>%
summarise(avg_score = mean(score))
merged <- merge(merged, avg_score, by='camis') %>%
select(3,4,7:9,11,13,27,31:33)
merged$cuisine.description <- str_replace_all(merged$cuisine.description, 'Latin\\s.*', 'Latin')
View(merged)
load("~/GitHub/CUNY_MSDS/Fall_2017/DATA_607/Final Project/.RData")
knitr::opts_chunk$set(echo = T,
cache = T,
stringsAsFactors = F)
library(tidyverse)
library(rvest)
library(httr)
library(googleVis)
library(jsonlite)
library(ggplot2)
library(nnet)
library(stringr)
library(here)
library(data.table)
library(plotly)
set.seed(1234)
merged <- merged[sample(nrow(merged)),]
split <- floor(nrow(merged)/2)
mergedTrain <- merged[0:split,]
mergedTest <- merged[(split+1):nrow(merged),]
ratModel <- multinom(rating~., data=mergedTrain)
View(merged)
library(here)
here()
knitr::opts_chunk$set(echo = T,
cache = F,
stringsAsFactors = F,
warning = F,
message = F)
here('GitHub', 'CUNY_MSDA', 'Fall_2017', 'DATA_606', 'Project Proposal')
here('GitHub', 'CUNY_MSDA', 'Fall_2017', 'DATA_606', 'Project Proposal')
setwd(here('GitHub', 'CUNY_MSDA', 'Fall_2017', 'DATA_606', 'Project Proposal'))
setwd("~/")
setwd('here('GitHub', 'CUNY_MSDA', 'Fall_2017', 'DATA_606', 'Project Proposal')')
setwd(here('GitHub', 'CUNY_MSDA', 'Fall_2017', 'DATA_606', 'Project Proposal'))
wed
wd
getwd()
set_here()
set_here()
here()
here('GitHub', 'CUNY_MSDA', 'Fall_2017', 'DATA_606', 'Project Proposal')
here()
set_here('GitHub', 'CUNY_MSDA', 'Fall_2017', 'DATA_606', 'Project Proposal')
here()
setwd(here('GitHub', 'CUNY_MSDA', 'Fall_2017', 'DATA_606', 'Project Proposal'))
getwd()
setwd(here('GitHub', 'CUNY_MSDA', 'Fall_2017', 'DATA_606', 'Project Proposal'))
knitr::opts_chunk$set(echo = T,
cache = F,
stringsAsFactors = F,
warning = F,
message = F)
#
# Load the files from the working directory
#
amendments_raw <- read.csv("amendment_list.csv")
members_raw <- read.csv("congress_terms.csv")
#
# Remove empty column, and remove all rows with missing data
#
bills <- read.csv("bills93-114.csv", header = T, na.strings = c('', 'NULL')) %>%
select(-7)
knitr::opts_chunk$set(echo = T,
cache = F,
stringsAsFactors = F,
warning = F,
message = F)
library(tidyverse)
library(ggplot2)
library(plotly)
library(here)
setwd(here('GitHub', 'CUNY_MSDA', 'Fall_2017', 'DATA_606', 'Project Proposal'))
#
# Load the files from the working directory
#
amendments_raw <- read.csv("amendment_list.csv")
members_raw <- read.csv("congress_terms.csv")
#
# Remove empty column, and remove all rows with missing data
#
bills <- read.csv("bills93-114.csv", header = T, na.strings = c('', 'NULL')) %>%
select(-7)
bills <- bills[complete.cases(bills), ]
#
# Tidy the datasets
#
# Keep only the relevant columns
amendments <- amendments_raw %>%
select(5, 7:ncol(amendments_raw)-1, -6)
# Use regex to shift errant data to their appropriate columns
for (i in 1:(length(amendments$year))) {
pat <- "\\D{3,}"
if (grepl(pat, amendments[i, "month"]) == 1)
{
amendments[i, "year"] <- amendments[i, "month"]
amendments[i, "month"] <- amendments[i, "day"]
amendments[i, "day"] <- amendments[i, "congress"]
amendments[i, "congress"] <- amendments[i, "congressional_session"]
amendments[i, "congressional_session"] <- amendments[i, "joint_resolution_chamber"]
}
}
amendments$year <- gsub("\\D{4}$", "", amendments$year)
members <- members_raw %>%
select(-c(3,7))
#
# Which years had the most bills?
#
by_year_graph <- ggplot(amendments, aes(year)) +
geom_bar() +
scale_x_discrete(breaks=seq(1788, 2014, 20))
by_year_graph <- ggplotly(by_year_graph)
by_year_graph
head(summary(amendments$title_or_description_from_source))
amendments <- amendments %>%
filter(!sponsor_state_or_territory %in% "")
by_state_graph <- ggplot(amendments, aes(sponsor_state_or_territory)) +
geom_bar() +
theme(axis.text.x = element_text(angle = 90))
#scale_x_discrete(breaks=seq(1788, 2014, 20))
by_state_graph <- ggplotly(by_state_graph)
by_state_graph
#
# Create new df of unique congressmen - remove duplicates
#
members_unique <- members %>%
distinct(lastname, birthday, .keep_all = T)
table(members_unique$party)
table(members_unique$incumbent)
summary(members$age)
age_year_graph <- ggplot(members, aes(congress, age)) +
geom_point() +
stat_summary(aes(y = age, group = 1), fun.y = mean, colour = "red", geom = "line", group = 1)
age_year_graph <- ggplotly(age_year_graph)
age_year_graph
formula <- 'PLaw ~ Age + ComC + CumHServ + District + Gender + Majority + Party + State'
model <- glm(formula= formula, data=bills, family=binomial(link="logit"))
summary(model)
anova(model, test="Chisq")
age_chart <- ggplot(bills, aes(x = Age)) +
geom_line(aes(fill = ..count..), stat = 'bin')
ggplotly(age_chart)
save.image("~/GitHub/CUNY_MSDA/Fall_2017/DATA_606/Project Proposal/.RData")
knitr::opts_chunk$set(echo = T,
cache = T,
stringsAsFactors = F,
warning = F,
message = F)
setNames(data.frame(table(bills$Age)),c("Age","Count"))
age_df <- setNames(data.frame(table(bills$Age)),c("Age","Count"))
View(age_df)
age_chart <- ggplot(bills, aes(x = Age)) +
geom_bar()
year_graph <- ggplot(bills, aes(Cong, Age)) +
geom_point() +
stat_summary(aes(y = Age, group = 1), fun.y = mean, colour = "red", geom = "line", group = 1)
year_graph <- ggplotly(year_graph)
year_graph
View(bills)
rm(age_df)
rm(year_graph)
save.image("~/GitHub/CUNY_MSDA/Fall_2017/DATA_606/Project Proposal/.RData")
